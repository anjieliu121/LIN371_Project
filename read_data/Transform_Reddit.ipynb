{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Read Reddit Data\n",
    "\n",
    "# Assumptions\n",
    "We are NOT using data from `reddit.l2.raw` because they are minimally processed.\n",
    "\n",
    "We assume every line in the 500K samples comes from a unique user.\n",
    "\n",
    "# Issues\n",
    "China is underrepresented.\n",
    "* Reason: this can be explained by Chinese people have limited access to Reddit due to the firewall.\n",
    "* Solution: randomly pick the same number of lines from the other countries.\n",
    "* Consequence: lose information for other countries\n",
    "* Benefits: we have smaller data to deal with"
   ],
   "id": "9b68d6982318813"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-26T05:07:32.393948Z",
     "start_time": "2024-11-26T05:07:32.387636Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import random"
   ],
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T05:07:51.690914Z",
     "start_time": "2024-11-26T05:07:51.686065Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "Read one file given the country name.\n",
    "When limit (number of lines to choose) is positive, choose a `limit` of comments at random.\n",
    "\n",
    "@param country: country name\n",
    "@param native_language: language used in that country\n",
    "@param limit: number of lines to randomly choose; if limit=-1, we maintain all the lines\n",
    "@return a dataframe of \"comments\" and \"native_language\" where \"native_language\" is set to one value\n",
    "\"\"\"\n",
    "def read_file(country, native_language, limit=-1):\n",
    "    file = open(f'../raw_data/reddit.l2/reddit.l2.clean.500K/reddit.{country}.txt.tok.clean.shf.500K.nometa.tc.noent.fw.url.lc', \"r\")\n",
    "    lines = file.readlines()\n",
    "    lines = [l.rstrip() for l in lines]\n",
    "    if limit > 0:\n",
    "        lines = random.sample(lines, limit)\n",
    "    df = pd.DataFrame({\"comments\": lines, \"native_language\": native_language})\n",
    "    print(f\"{country}: {len(lines)} lines\")\n",
    "    return df"
   ],
   "id": "fd2b1c3ae143ef92",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T05:13:34.230277Z",
     "start_time": "2024-11-26T05:13:34.224126Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "Read files related to selected countries.\n",
    "\"limit\" is set to an arbitrary number of 125073 because this is the maximum number of lines the Chinese document has.\n",
    "\n",
    "@param countries: a dictionary where key = country name and value = language of that country\n",
    "@return a dataframe of \"comments\" and \"native_language\" of all comments of the given countries\n",
    "\"\"\"\n",
    "def read_countries(countries):\n",
    "    df = pd.DataFrame()\n",
    "    for country in countries.keys():\n",
    "        temp = read_file(country, countries[country], limit=125073)\n",
    "        df = pd.concat([df, temp], ignore_index=True)\n",
    "    return df"
   ],
   "id": "ab6fce6fe0ed994d",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T05:08:08.218158Z",
     "start_time": "2024-11-26T05:08:07.356802Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "Get dataframe of comments of selected countries.\n",
    "\"\"\"\n",
    "countries = {\n",
    "    \"China\": \"Chinese\",\n",
    "    \"France\": \"French\",\n",
    "    \"Germany\": \"German\",\n",
    "    \"Greece\": \"Greek\",\n",
    "    \"Portugal\": \"Portuguese\",\n",
    "    \"Spain\": \"Spanish\"\n",
    "}\n",
    "df = read_countries(countries)\n",
    "df"
   ],
   "id": "f56cd7afa422fe5c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "China: 125073 lines\n",
      "France: 125073 lines\n",
      "Germany: 125073 lines\n",
      "Greece: 125073 lines\n",
      "Portugal: 125073 lines\n",
      "Spain: 125073 lines\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                                                 comments native_language\n",
       "0       she was born , lived and died on these soils w...         Chinese\n",
       "1                         her books are a waste of time .         Chinese\n",
       "2       here 's a previous thread where i posted the s...         Chinese\n",
       "3                   NORP are from GPE which is not in LOC         Chinese\n",
       "4       GPE tries to heavily promote uniquely NORP fac...         Chinese\n",
       "...                                                   ...             ...\n",
       "750433  > not according to the project website , libre...         Spanish\n",
       "750434  did you see that all that has nothing to do wi...         Spanish\n",
       "750435  then what has them saying it CARDINAL times to...         Spanish\n",
       "750436  which i do n't have access to and i 'd have to...         Spanish\n",
       "750437                                - sleek contour kit         Spanish\n",
       "\n",
       "[750438 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>native_language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>she was born , lived and died on these soils w...</td>\n",
       "      <td>Chinese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>her books are a waste of time .</td>\n",
       "      <td>Chinese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>here 's a previous thread where i posted the s...</td>\n",
       "      <td>Chinese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NORP are from GPE which is not in LOC</td>\n",
       "      <td>Chinese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GPE tries to heavily promote uniquely NORP fac...</td>\n",
       "      <td>Chinese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750433</th>\n",
       "      <td>&gt; not according to the project website , libre...</td>\n",
       "      <td>Spanish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750434</th>\n",
       "      <td>did you see that all that has nothing to do wi...</td>\n",
       "      <td>Spanish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750435</th>\n",
       "      <td>then what has them saying it CARDINAL times to...</td>\n",
       "      <td>Spanish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750436</th>\n",
       "      <td>which i do n't have access to and i 'd have to...</td>\n",
       "      <td>Spanish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750437</th>\n",
       "      <td>- sleek contour kit</td>\n",
       "      <td>Spanish</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>750438 rows Ã— 2 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T05:09:17.404266Z",
     "start_time": "2024-11-26T05:09:16.482561Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "Export dataframe to CSV file.\n",
    "\"\"\"\n",
    "df.to_csv(\"data/reddit_6languages.csv\", index=False)"
   ],
   "id": "3ba59457b8b3053c",
   "outputs": [],
   "execution_count": 28
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
